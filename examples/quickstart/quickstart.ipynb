{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO_v5iIaYFi2"
   },
   "source": [
    "# ZenML Quickstart Guide\n",
    "\n",
    "Our goal here is to help you to get the first practical experience with our tool and give you a brief overview on some basic functionalities of ZenML. We'll create a training pipeline for the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset and then later the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset developed by Zalando.\n",
    "\n",
    "If you want to run this notebook in an interactive environment, feel free to run it in a [Google Colab](https://colab.research.google.com/github/zenml-io/zenml/blob/main/examples/quickstart/quickstart.ipynb) or view it on [GitHub](https://github.com/zenml-io/zenml/tree/main/examples/quickstart) directly.\n",
    "\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This quickstart guide is designed to provide a practical introduction to some of the main concepts and paradigms used by the ZenML framework. If you want more detail, our [full documentation](https://docs.zenml.io/) provides more on the concepts and how to implement them.\n",
    "\n",
    "## Using Google Colab\n",
    "\n",
    "You will want to use a GPU for this example. If you are following this quickstart in Google's Colab, follow these steps:\n",
    "\n",
    "- Before running anything, you need to tell Colab that you want to use a GPU. You can do this by clicking on the ‘Runtime’ tab and selecting ‘Change runtime type’. A pop-up window will open up with a drop-down menu.\n",
    "- Select ‘GPU’ from the menu and click ‘Save’.\n",
    "- It may ask if you want to restart the runtime. If so, go ahead and do that.\n",
    "\n",
    "<!-- The code for the MNIST training borrows heavily from [this](https://www.tensorflow.org/datasets/keras_example) -->\n",
    "\n",
    "## Relation to quickstart.py\n",
    "This notebook is a variant of [quickstart.py](https://github.com/zenml-io/zenml/blob/main/examples/quickstart/quickstart.py) which is shown off in the [ZenML Docs](https://docs.zenml.io). The core difference being it adds a modular aspect of the importer step and shows how to fetch pipelines, runs, and artifacts in the post-execution workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNLEesHEyjkg"
   },
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!zenml profile create quickstart\n",
    "!zenml profile set quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x7l4qDgcI_5F",
    "outputId": "ed764976-0d95-4e5f-e75d-805d2bab804c"
   },
   "outputs": [],
   "source": [
    "# Install the ZenML CLI tool and Tensorflow\n",
    "!pip install zenml matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zenml integration install sklearn mlflow evidently facets -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import display_restart_button\n",
    "\n",
    "display_restart_button()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_RCPyaNzPy-"
   },
   "source": [
    "Once the installation is completed, you can go ahead and create your first ZenML repository for your project. As ZenML repositories are built on top of Git repositories, you can create yours in a desired empty directory through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lcfE3l2zTU-",
    "outputId": "3d3e70af-c87a-4ac9-917d-b322823431e1"
   },
   "outputs": [],
   "source": [
    "# Initialize a ZenML repository\n",
    "!zenml init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQE8PSXDzL-_"
   },
   "source": [
    "Now, the setup is completed. For the next steps, just make sure that you are executing the code within your ZenML repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a MLOps Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of a stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the MLflow experiment tracker\n",
    "!zenml experiment-tracker register mlflow_tracker --flavor=mlflow\n",
    "\n",
    "# Add the MLflow experiment tracker into our default stack\n",
    "!zenml stack update default -e mlflow_tracker\n",
    "\n",
    "# Register the MLflow model deployer\n",
    "!zenml model-deployer register mlflow_deployer --flavor=mlflow\n",
    "\n",
    "# Add the MLflow model deployer into our default stack\n",
    "!zenml stack update default -d mlflow_deployer\n",
    "\n",
    "# Set it to default\n",
    "!zenml stack set default\n",
    "\n",
    "# Visualize it\n",
    "!zenml stack describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izjbDO-6yrFM"
   },
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gtj5QKCnSj0"
   },
   "source": [
    "We will use pipelines and steps to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LvFo9epOUE7G",
    "outputId": "42bec4a0-41f9-4560-e9a1-e139f08c4e0a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.svm import SVC\n",
    "from zenml.integrations.sklearn.helpers.digits import get_digits\n",
    "from zenml.steps import step, Output\n",
    "from zenml.pipelines import pipeline\n",
    "from zenml.integrations.mlflow.mlflow_step_decorator import enable_mlflow\n",
    "\n",
    "from zenml.integrations.mlflow.steps import mlflow_model_deployer_step\n",
    "from zenml.integrations.evidently.steps import (\n",
    "    EvidentlyProfileConfig,\n",
    "    EvidentlyProfileStep,\n",
    ")\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwqjAR2yvH_"
   },
   "source": [
    "## Define ZenML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wHcI2FinX2O"
   },
   "source": [
    "In the code that follows, you can see that we are defining the various steps of our pipeline. Each step is decorated with `@step`, the main abstraction that is currently available for creating pipeline steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZI9i2FJ0k3H"
   },
   "source": [
    "The first step is an `import` step that downloads the MNIST dataset and returns four numpy arrays as its output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VT_PAW10jbp",
    "outputId": "36ecdd08-3bca-42b4-d84d-be76126840e8"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def importer() -> Output(\n",
    "    X_train=np.ndarray,\n",
    "    X_test=np.ndarray,\n",
    "    y_train=np.ndarray,\n",
    "    y_test=np.ndarray,\n",
    "):\n",
    "    \"\"\"Load the digits dataset as numpy arrays.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = get_digits()\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ma53mucU0yF3"
   },
   "source": [
    "We then add a `Trainer` step, that takes the imported data and trains a sklearn classifier on the data. Note that the model is not explicitly saved within the step. Under the hood ZenML uses Materializers to automatically persist the Artifacts that result from each step into the Artifact Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEw7Cbqx0wXj",
    "outputId": "0603fa51-eb20-4c22-d499-9e7f1f3a972b"
   },
   "outputs": [],
   "source": [
    "@enable_mlflow  # setup MLflow\n",
    "@step(enable_cache=False)\n",
    "def svc_trainer_mlflow(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    ") -> ClassifierMixin:\n",
    "    \"\"\"Train a sklearn SVC classifier and log to MLflow.\"\"\"\n",
    "    mlflow.sklearn.autolog()  # log all model hparams and metrics to MLflow\n",
    "    model = SVC(gamma=0.01)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aU9ygH9s1BgR"
   },
   "source": [
    "Finally, we add an `Evaluator` step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37mMICD_URDW",
    "outputId": "873fe64b-1105-4181-8541-c31356069305"
   },
   "outputs": [],
   "source": [
    "@step\n",
    "def evaluator(\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    model: ClassifierMixin,\n",
    ") -> float:\n",
    "    \"\"\"Calculate the test set accuracy of an sklearn model.\"\"\"\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add an `Deployer` step that takes as input the test set and the trained model and evaluates some final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def deployment_trigger(val_acc: float) -> bool:\n",
    "    \"\"\"Only deploy if the validation accuracy > 90%.\"\"\"\n",
    "    return val_acc > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also add a drift detection step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@step\n",
    "def get_reference_data(\n",
    "    X_train: np.ndarray,\n",
    "    X_test: np.ndarray,\n",
    ") -> Output(reference=pd.DataFrame, comparison=pd.DataFrame):\n",
    "    \"\"\"Splits data for drift detection.\"\"\"\n",
    "    # X_train = _add_awgn(X_train)\n",
    "    columns = [str(x) for x in list(range(X_train.shape[1]))]\n",
    "    return pd.DataFrame(X_test, columns=columns), pd.DataFrame(\n",
    "        X_train, columns=columns\n",
    "    )\n",
    "\n",
    "evidently_profile_config = EvidentlyProfileConfig(\n",
    "    column_mapping=None, profile_sections=[\"datadrift\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_iZTIz8y7Cp"
   },
   "source": [
    "## Define ZenML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKbU3WlbnoiA"
   },
   "source": [
    "A pipeline is defined with the `@pipeline` decorator. This defines the various steps of the pipeline and specifies the dependencies between the steps, thereby determining the order in which they will be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rm8SIrLFWenn"
   },
   "outputs": [],
   "source": [
    "@pipeline(enable_cache=False)\n",
    "def quickstart_pipeline(\n",
    "    importer,\n",
    "    trainer,\n",
    "    evaluator,\n",
    "    \n",
    "    get_reference_data,\n",
    "    drift_detector,\n",
    "    \n",
    "    deployment_trigger,\n",
    "    model_deployer,\n",
    "):\n",
    "    \"\"\"Train and deploy a model with MLflow.\"\"\"\n",
    "    X_train, X_test, y_train, y_test = importer()\n",
    "    model = trainer(X_train=X_train, y_train=y_train)\n",
    "    test_acc = evaluator(X_test=X_test, y_test=y_test, model=model)\n",
    "    \n",
    "    reference, comparison = get_reference_data(X_train, X_test)\n",
    "    drift_report, _ = drift_detector(reference, comparison)\n",
    "    \n",
    "    deployment_decision = deployment_trigger(test_acc)  # new\n",
    "    model_deployer(deployment_decision, model)  # new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-JtDHu_z1IX"
   },
   "source": [
    "## Run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrJA5OSgnydC"
   },
   "source": [
    "Running the pipeline is as simple as calling the `run()` method on an instance of the defined pipeline. Here we explicitly name our pipeline run to make it easier to access later on. Be aware that you can only run the pipeline once with this name. To rerun, rename the the run, or remove the run name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRzZA406UVVz",
    "outputId": "2d5e9967-87b7-4553-a104-b1b6602e10a6"
   },
   "outputs": [],
   "source": [
    "p = quickstart_pipeline(\n",
    "    importer=importer(),\n",
    "    trainer=svc_trainer_mlflow(),\n",
    "    evaluator=evaluator(),\n",
    "    \n",
    "    get_reference_data=get_reference_data(),\n",
    "    drift_detector=EvidentlyProfileStep(config=evidently_profile_config),\n",
    "    \n",
    "    deployment_trigger=deployment_trigger(),\n",
    "    model_deployer=mlflow_model_deployer_step(),\n",
    ")\n",
    "\n",
    "p.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-execution: After running the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the latest pipeline run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, we load your repository: this is where all your pipelines live. This is how you get all of the pipelines within your repository. We could now just take the pipeline from above by index using `pipelines[0]`. \n",
    "Alternatively we can get our pipelines by name from our repo. The name of the pipeline defaults to the function name, if not specified. All runs are saved chronologically within the corresponding pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.repository import Repository\n",
    "\n",
    "repo = Repository()\n",
    "pipelines = repo.get_pipelines()\n",
    "my_pipeline = repo.get_pipeline(pipeline_name=\"quickstart_pipeline\")\n",
    "latest_run = my_pipeline.runs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full explaination in Link to example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifact Lineage and Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.dash.visualizers.pipeline_run_lineage_visualizer import (\n",
    "    PipelineRunLineageVisualizer,\n",
    ")\n",
    "\n",
    "PipelineRunLineageVisualizer().visualize(latest_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full explaination in Link to example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.facets.visualizers.facet_statistics_visualizer import (\n",
    "    FacetStatisticsVisualizer,\n",
    ")\n",
    "\n",
    "outputs = latest_run.get_step(name=\"get_reference_data\")\n",
    "FacetStatisticsVisualizer().visualize(outputs, magic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full explaination in Link to example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View pipelines as ML experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will start a serving process for mlflow\n",
    "#  - if you want to continue in the notebook you need to manually\n",
    "#  interrupt the kernel\n",
    "from zenml.integrations.mlflow.mlflow_utils import get_tracking_uri\n",
    "import IPython\n",
    "\n",
    "get_ipython().system_raw(f'mlflow ui --backend-store-uri=\"{get_tracking_uri()}\" --port=4997 &') \n",
    "display(IPython.display.HTML('<script src=\"https://localhost:4997\"></script>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full explaination in Link to example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenml.integrations.evidently.visualizers import EvidentlyVisualizer\n",
    "\n",
    "drift_detection_step = latest_run.get_step(name=\"drift_detector\")\n",
    "EvidentlyVisualizer().visualize(drift_detection_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full explaination in Link to example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_deployer = repo.active_stack.model_deployer\n",
    "services = model_deployer.find_model_server(\n",
    "    pipeline_name=\"quickstart_pipeline\",\n",
    "    pipeline_step_name=\"mlflow_model_deployer_step\",\n",
    "    running=True,\n",
    ")\n",
    "service = services[0]\n",
    "service.check_status()\n",
    "\n",
    "X_test = latest_run.steps[0].outputs[\"X_test\"].read()\n",
    "y_test = latest_run.steps[0].outputs[\"y_test\"].read()\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(X_test[0].reshape(8, 8), cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "pred0 = service.predict(X_test[0:1])\n",
    "print(f\"Model predicted {pred0}, true label was {y_test[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Full explaination in Link to example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to add here a bunch of stuff about \n",
    "\n",
    "* ZenBytes\n",
    "* ZenFiles\n",
    "* Running on a cloud stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOJtVVaFzlUO"
   },
   "source": [
    "… and that's it for the quickstart. If you came here without a hiccup, you must have successly installed ZenML, set up a ZenML repo, configured a training pipeline, executed it and evaluated the results. And, this is just the tip of the iceberg on the capabilities of ZenML.\n",
    "\n",
    "However, if you had a hiccup or you have some suggestions/questions regarding our framework, you can always check our [docs](https://docs.zenml.io/) or our [Github](https://github.com/zenml-io/zenml) or even better join us on our [Slack channel](https://zenml.io/slack-invite).\n",
    "\n",
    "Cheers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22gkBKSntlF8"
   },
   "source": [
    "For more detailed information on all the components and steps that went into this short example, please continue reading [our more detailed documentation pages](https://docs.zenml.io/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "ZenML Quickstart.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
